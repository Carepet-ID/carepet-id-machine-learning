{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67af00b7",
   "metadata": {
    "papermill": {
     "duration": 0.006447,
     "end_time": "2024-06-06T07:01:51.014676",
     "exception": false,
     "start_time": "2024-06-06T07:01:51.008229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DOG DISEASE DETECTION\n",
    "## Tim : \n",
    "- Christian adi Ananta\n",
    "- Ezra Abednego\n",
    "\n",
    "### Dataset : \n",
    "\n",
    "### Metode : \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bec5d629",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T07:01:51.028219Z",
     "iopub.status.busy": "2024-06-06T07:01:51.027804Z",
     "iopub.status.idle": "2024-06-06T07:01:51.040028Z",
     "shell.execute_reply": "2024-06-06T07:01:51.039140Z"
    },
    "papermill": {
     "duration": 0.021431,
     "end_time": "2024-06-06T07:01:51.042214",
     "exception": false,
     "start_time": "2024-06-06T07:01:51.020783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e0ac47e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T07:01:51.055787Z",
     "iopub.status.busy": "2024-06-06T07:01:51.054917Z",
     "iopub.status.idle": "2024-06-06T07:03:13.708338Z",
     "shell.execute_reply": "2024-06-06T07:03:13.707344Z"
    },
    "papermill": {
     "duration": 82.66276,
     "end_time": "2024-06-06T07:03:13.710878",
     "exception": false,
     "start_time": "2024-06-06T07:01:51.048118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.13.0\r\n",
      "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (23.5.26)\r\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.13.0)\r\n",
      "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (0.2.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (1.51.1)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (3.10.0)\r\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13.0)\r\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (16.0.6)\r\n",
      "Collecting numpy<=1.24.3,>=1.22 (from tensorflow==2.13.0)\r\n",
      "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (21.3)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (69.0.3)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (1.16.0)\r\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow==2.13.0)\r\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\r\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13.0)\r\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (2.4.0)\r\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow==2.13.0)\r\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (1.14.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (0.35.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.42.0)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.26.1)\r\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow==2.13.0)\r\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.5.2)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.31.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow==2.13.0) (3.1.1)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.3.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2024.2.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.1.3)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.5.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\r\n",
      "Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\r\n",
      "Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\r\n",
      "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\r\n",
      "Installing collected packages: typing-extensions, tensorflow-estimator, numpy, keras, gast, google-auth-oauthlib, tensorboard, tensorflow\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.9.0\r\n",
      "    Uninstalling typing_extensions-4.9.0:\r\n",
      "      Successfully uninstalled typing_extensions-4.9.0\r\n",
      "  Attempting uninstall: tensorflow-estimator\r\n",
      "    Found existing installation: tensorflow-estimator 2.15.0\r\n",
      "    Uninstalling tensorflow-estimator-2.15.0:\r\n",
      "      Successfully uninstalled tensorflow-estimator-2.15.0\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.26.4\r\n",
      "    Uninstalling numpy-1.26.4:\r\n",
      "      Successfully uninstalled numpy-1.26.4\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 3.2.1\r\n",
      "    Uninstalling keras-3.2.1:\r\n",
      "      Successfully uninstalled keras-3.2.1\r\n",
      "  Attempting uninstall: gast\r\n",
      "    Found existing installation: gast 0.5.4\r\n",
      "    Uninstalling gast-0.5.4:\r\n",
      "      Successfully uninstalled gast-0.5.4\r\n",
      "  Attempting uninstall: google-auth-oauthlib\r\n",
      "    Found existing installation: google-auth-oauthlib 1.2.0\r\n",
      "    Uninstalling google-auth-oauthlib-1.2.0:\r\n",
      "      Successfully uninstalled google-auth-oauthlib-1.2.0\r\n",
      "  Attempting uninstall: tensorboard\r\n",
      "    Found existing installation: tensorboard 2.15.1\r\n",
      "    Uninstalling tensorboard-2.15.1:\r\n",
      "      Successfully uninstalled tensorboard-2.15.1\r\n",
      "  Attempting uninstall: tensorflow\r\n",
      "    Found existing installation: tensorflow 2.15.0\r\n",
      "    Uninstalling tensorflow-2.15.0:\r\n",
      "      Successfully uninstalled tensorflow-2.15.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf 23.8.0 requires cubinlinker, which is not installed.\r\n",
      "cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cudf 23.8.0 requires ptxcompiler, which is not installed.\r\n",
      "cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "keras-nlp 0.9.3 requires keras-core, which is not installed.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "sqlalchemy 2.0.25 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\r\n",
      "albumentations 1.4.0 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\r\n",
      "cudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\r\n",
      "cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "cudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.2 which is incompatible.\r\n",
      "cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\r\n",
      "dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\r\n",
      "dask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "fastapi 0.108.0 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\r\n",
      "featuretools 1.30.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\r\n",
      "jupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "pydantic 2.5.3 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\r\n",
      "pydantic-core 2.14.6 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\r\n",
      "pylibraft 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\r\n",
      "raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\r\n",
      "rmm 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.8.1 requires tensorflow~=2.15.0, but you have tensorflow 2.13.0 which is incompatible.\r\n",
      "tensorflow-serving-api 2.14.1 requires tensorflow<3,>=2.14.1, but you have tensorflow 2.13.0 which is incompatible.\r\n",
      "tensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.13.0 which is incompatible.\r\n",
      "tensorstore 0.1.56 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\r\n",
      "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.13.0 which is incompatible.\r\n",
      "typeguard 4.1.5 requires typing-extensions>=4.7.0; python_version < \"3.12\", but you have typing-extensions 4.5.0 which is incompatible.\r\n",
      "woodwork 0.30.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\r\n",
      "xarray 2024.3.0 requires packaging>=22, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 keras-2.13.1 numpy-1.24.3 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 typing-extensions-4.5.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b43bca7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T07:03:13.757289Z",
     "iopub.status.busy": "2024-06-06T07:03:13.756510Z",
     "iopub.status.idle": "2024-06-06T07:03:19.817346Z",
     "shell.execute_reply": "2024-06-06T07:03:19.816137Z"
    },
    "papermill": {
     "duration": 6.086137,
     "end_time": "2024-06-06T07:03:19.819620",
     "exception": false,
     "start_time": "2024-06-06T07:03:13.733483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82604047",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T07:03:19.866035Z",
     "iopub.status.busy": "2024-06-06T07:03:19.864920Z",
     "iopub.status.idle": "2024-06-06T07:03:19.892293Z",
     "shell.execute_reply": "2024-06-06T07:03:19.891473Z"
    },
    "papermill": {
     "duration": 0.052591,
     "end_time": "2024-06-06T07:03:19.894671",
     "exception": false,
     "start_time": "2024-06-06T07:03:19.842080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from shutil import copyfile\n",
    "from PIL import Image \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from shutil import copyfile\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "379b0983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T07:03:19.939873Z",
     "iopub.status.busy": "2024-06-06T07:03:19.939038Z",
     "iopub.status.idle": "2024-06-06T07:03:19.947873Z",
     "shell.execute_reply": "2024-06-06T07:03:19.946845Z"
    },
    "papermill": {
     "duration": 0.033019,
     "end_time": "2024-06-06T07:03:19.949861",
     "exception": false,
     "start_time": "2024-06-06T07:03:19.916842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cat images: ['earinfection', 'dermatitis', 'skintumors', 'fleas', 'dandruff', 'ringworm']\n"
     ]
    }
   ],
   "source": [
    "#Cek File Dataset\n",
    "print(\"Number of cat images:\",os.listdir('/kaggle/input/skin-disease-dog-augmented/Skin_Disease_Augment'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50fa27b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T07:03:19.996135Z",
     "iopub.status.busy": "2024-06-06T07:03:19.995355Z",
     "iopub.status.idle": "2024-06-06T07:03:20.002316Z",
     "shell.execute_reply": "2024-06-06T07:03:20.001562Z"
    },
    "papermill": {
     "duration": 0.03293,
     "end_time": "2024-06-06T07:03:20.004381",
     "exception": false,
     "start_time": "2024-06-06T07:03:19.971451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Membuat Folder Train Dan Validation\n",
    "from pathlib import Path\n",
    "path_img='/kaggle/input/skin-disease-dog-augmented/Skin_Disease_Augment'\n",
    "img_directory=os.listdir(path_img)\n",
    "work_path = Path('/kaggle/working/')\n",
    "for i in [\"train\",\"validation\"]:\n",
    "    work_path_parent = Path('/kaggle/working/'+i)\n",
    "    work_path_parent.mkdir(exist_ok=True)\n",
    "    for j in img_directory:\n",
    "        work_path = Path('/kaggle/working/'+i+\"/\"+j)\n",
    "        work_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12f2538c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T07:03:20.050084Z",
     "iopub.status.busy": "2024-06-06T07:03:20.049471Z",
     "iopub.status.idle": "2024-06-06T07:03:43.964265Z",
     "shell.execute_reply": "2024-06-06T07:03:43.963157Z"
    },
    "papermill": {
     "duration": 23.941663,
     "end_time": "2024-06-06T07:03:43.967860",
     "exception": false,
     "start_time": "2024-06-06T07:03:20.026197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split Data dengan presentase 90% Train dan 10% Validation\n",
    "def split_data(split_size):\n",
    "    files=[]\n",
    "    for file_dir in img_directory:\n",
    "        name_image=[]\n",
    "        for filename in os.listdir(path_img+\"/\"+file_dir):\n",
    "            file=path_img+\"/\"+file_dir+\"/\"+filename\n",
    "            if os.path.getsize(file) > 0:\n",
    "                name_image.append(filename)\n",
    "            else:\n",
    "                print(filename + \" is zero length, so ignoring.\")\n",
    "        files.append(name_image)\n",
    "    for index,path_image in enumerate(files):\n",
    "        train_len=int(len(path_image)*split_size)\n",
    "        shuffle=random.sample(path_image,len(path_image))\n",
    "        train_data=path_image[:train_len]\n",
    "        validation_data=path_image[train_len:]\n",
    "        for filename in train_data:\n",
    "            file=path_img+\"/\"+img_directory[index]+\"/\"+filename\n",
    "            destination=\"/kaggle/working/train/\"+img_directory[index]+\"/\"+filename\n",
    "            copyfile(file,destination)\n",
    "        for filename in validation_data:\n",
    "            file=path_img+\"/\"+img_directory[index]+\"/\"+filename\n",
    "            destination=\"/kaggle/working/validation/\"+img_directory[index]+\"/\"+filename\n",
    "            copyfile(file,destination)\n",
    "        \n",
    "split_size=.8\n",
    "split_data(split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ec49227",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T07:03:44.011544Z",
     "iopub.status.busy": "2024-06-06T07:03:44.010794Z",
     "iopub.status.idle": "2024-06-06T07:03:44.182997Z",
     "shell.execute_reply": "2024-06-06T07:03:44.181957Z"
    },
    "papermill": {
     "duration": 0.196401,
     "end_time": "2024-06-06T07:03:44.185393",
     "exception": false,
     "start_time": "2024-06-06T07:03:43.988992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3599 images belonging to 6 classes.\n",
      "Found 901 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Melakukan preprocessing data image dari directory\n",
    "\n",
    "TRAINING_DIR = \"/kaggle/working/train\"\n",
    "# Experiment with your own parameters to reach 99.9% validation accuracy or better\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   horizontal_flip=True,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   fill_mode='nearest')\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    target_size=(150, 150))\n",
    "VALIDATION_DIR = \"/kaggle/working/validation/\"\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                              batch_size=32,\n",
    "                                                              class_mode='categorical',\n",
    "                                                              target_size=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4f96a31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T07:03:44.229629Z",
     "iopub.status.busy": "2024-06-06T07:03:44.228801Z",
     "iopub.status.idle": "2024-06-06T07:03:44.232985Z",
     "shell.execute_reply": "2024-06-06T07:03:44.232088Z"
    },
    "papermill": {
     "duration": 0.028259,
     "end_time": "2024-06-06T07:03:44.234869",
     "exception": false,
     "start_time": "2024-06-06T07:03:44.206610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_augmentation = tf.keras.Sequential([\n",
    "#   tf.keras.layers.RandomFlip('horizontal'),\n",
    "#   tf.keras.layers.RandomRotation(0.2),\n",
    "# ])\n",
    "\n",
    "# preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7635513d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T07:03:44.279927Z",
     "iopub.status.busy": "2024-06-06T07:03:44.279042Z",
     "iopub.status.idle": "2024-06-06T07:03:47.748075Z",
     "shell.execute_reply": "2024-06-06T07:03:47.747244Z"
    },
    "papermill": {
     "duration": 3.494078,
     "end_time": "2024-06-06T07:03:47.750473",
     "exception": false,
     "start_time": "2024-06-06T07:03:44.256395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model =  tf.keras.applications.InceptionV3(input_shape=(150,150,3),\n",
    "                                                       include_top=False,\n",
    "                                                       weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61d500b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T07:03:47.795393Z",
     "iopub.status.busy": "2024-06-06T07:03:47.795000Z",
     "iopub.status.idle": "2024-06-06T07:03:47.812220Z",
     "shell.execute_reply": "2024-06-06T07:03:47.811380Z"
    },
    "papermill": {
     "duration": 0.042252,
     "end_time": "2024-06-06T07:03:47.814496",
     "exception": false,
     "start_time": "2024-06-06T07:03:47.772244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#freeze layer\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16e4e634",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T07:03:47.860581Z",
     "iopub.status.busy": "2024-06-06T07:03:47.859795Z",
     "iopub.status.idle": "2024-06-06T07:03:47.865236Z",
     "shell.execute_reply": "2024-06-06T07:03:47.864348Z"
    },
    "papermill": {
     "duration": 0.030384,
     "end_time": "2024-06-06T07:03:47.867207",
     "exception": false,
     "start_time": "2024-06-06T07:03:47.836823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get last layer\n",
    "last_layer =  pre_trained_model.get_layer('mixed7')\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a53d3357",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T07:03:47.913561Z",
     "iopub.status.busy": "2024-06-06T07:03:47.912759Z",
     "iopub.status.idle": "2024-06-06T07:03:48.631607Z",
     "shell.execute_reply": "2024-06-06T07:03:48.630524Z"
    },
    "papermill": {
     "duration": 0.942302,
     "end_time": "2024-06-06T07:03:48.831025",
     "exception": false,
     "start_time": "2024-06-06T07:03:47.888723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 150, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 74, 74, 32)           864       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 74, 74, 32)           96        ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 74, 74, 32)           0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 32)           9216      ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 72, 72, 32)           96        ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 72, 72, 32)           0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 72, 72, 64)           18432     ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 72, 72, 64)           192       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, 72, 72, 64)           0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 35, 35, 64)           0         ['activation_2[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 35, 35, 80)           5120      ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 35, 35, 80)           240       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 35, 35, 80)           0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 33, 33, 192)          138240    ['activation_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 33, 33, 192)          576       ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 33, 33, 192)          0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 16, 16, 192)          0         ['activation_4[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 64)           12288     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 16, 16, 64)           192       ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)   (None, 16, 16, 64)           0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 16, 16, 48)           9216      ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 16, 16, 96)           55296     ['activation_8[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 16, 16, 48)           144       ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 16, 16, 96)           288       ['conv2d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (None, 16, 16, 48)           0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (None, 16, 16, 96)           0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " average_pooling2d (Average  (None, 16, 16, 192)          0         ['max_pooling2d_1[0][0]']     \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 64)           12288     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 16, 16, 64)           76800     ['activation_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 16, 16, 96)           82944     ['activation_9[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 16, 16, 32)           6144      ['average_pooling2d[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 16, 16, 64)           192       ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 16, 16, 64)           192       ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 16, 16, 96)           288       ['conv2d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 16, 16, 32)           96        ['conv2d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 16, 16, 64)           0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, 16, 16, 64)           0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, 16, 16, 32)           0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)        (None, 16, 16, 256)          0         ['activation_5[0][0]',        \n",
      "                                                                     'activation_7[0][0]',        \n",
      "                                                                     'activation_10[0][0]',       \n",
      "                                                                     'activation_11[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 16, 16, 64)           192       ['conv2d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_15 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 16, 16, 48)           12288     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 16, 16, 96)           55296     ['activation_15[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 16, 16, 48)           144       ['conv2d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 16, 16, 96)           288       ['conv2d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_13 (Activation)  (None, 16, 16, 48)           0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_16 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (Avera  (None, 16, 16, 256)          0         ['mixed0[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 16, 16, 64)           76800     ['activation_13[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 16, 16, 96)           82944     ['activation_16[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 16, 16, 64)           16384     ['average_pooling2d_1[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 16, 16, 64)           192       ['conv2d_12[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 16, 16, 64)           192       ['conv2d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 16, 16, 96)           288       ['conv2d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (None, 16, 16, 64)           192       ['conv2d_18[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_14 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_17 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_18 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)        (None, 16, 16, 288)          0         ['activation_12[0][0]',       \n",
      "                                                                     'activation_14[0][0]',       \n",
      "                                                                     'activation_17[0][0]',       \n",
      "                                                                     'activation_18[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (None, 16, 16, 64)           192       ['conv2d_22[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_22 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_22[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 16, 16, 48)           13824     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 16, 16, 96)           55296     ['activation_22[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (None, 16, 16, 48)           144       ['conv2d_20[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_23 (Ba  (None, 16, 16, 96)           288       ['conv2d_23[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_20 (Activation)  (None, 16, 16, 48)           0         ['batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_23 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_23[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (Avera  (None, 16, 16, 288)          0         ['mixed1[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 16, 16, 64)           76800     ['activation_20[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, 16, 16, 96)           82944     ['activation_23[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, 16, 16, 64)           18432     ['average_pooling2d_2[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (None, 16, 16, 64)           192       ['conv2d_19[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (None, 16, 16, 64)           192       ['conv2d_21[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_24 (Ba  (None, 16, 16, 96)           288       ['conv2d_24[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_25 (Ba  (None, 16, 16, 64)           192       ['conv2d_25[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_19 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_21 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_24 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_24[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_25 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_25[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)        (None, 16, 16, 288)          0         ['activation_19[0][0]',       \n",
      "                                                                     'activation_21[0][0]',       \n",
      "                                                                     'activation_24[0][0]',       \n",
      "                                                                     'activation_25[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, 16, 16, 64)           18432     ['mixed2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_27 (Ba  (None, 16, 16, 64)           192       ['conv2d_27[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_27 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_27[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (None, 16, 16, 96)           55296     ['activation_27[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_28 (Ba  (None, 16, 16, 96)           288       ['conv2d_28[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_28 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_28[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (None, 7, 7, 384)            995328    ['mixed2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)          (None, 7, 7, 96)             82944     ['activation_28[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_26 (Ba  (None, 7, 7, 384)            1152      ['conv2d_26[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_29 (Ba  (None, 7, 7, 96)             288       ['conv2d_29[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_26 (Activation)  (None, 7, 7, 384)            0         ['batch_normalization_26[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_29 (Activation)  (None, 7, 7, 96)             0         ['batch_normalization_29[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 7, 7, 288)            0         ['mixed2[0][0]']              \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)        (None, 7, 7, 768)            0         ['activation_26[0][0]',       \n",
      "                                                                     'activation_29[0][0]',       \n",
      "                                                                     'max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)          (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_34 (Ba  (None, 7, 7, 128)            384       ['conv2d_34[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_34 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_34[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)          (None, 7, 7, 128)            114688    ['activation_34[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_35 (Ba  (None, 7, 7, 128)            384       ['conv2d_35[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_35 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_35[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)          (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)          (None, 7, 7, 128)            114688    ['activation_35[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_31 (Ba  (None, 7, 7, 128)            384       ['conv2d_31[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_36 (Ba  (None, 7, 7, 128)            384       ['conv2d_36[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_31 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_31[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_36 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_36[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)          (None, 7, 7, 128)            114688    ['activation_31[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)          (None, 7, 7, 128)            114688    ['activation_36[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_32 (Ba  (None, 7, 7, 128)            384       ['conv2d_32[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_37 (Ba  (None, 7, 7, 128)            384       ['conv2d_37[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_32 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_32[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_37 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_37[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (Avera  (None, 7, 7, 768)            0         ['mixed3[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (None, 7, 7, 192)            172032    ['activation_32[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)          (None, 7, 7, 192)            172032    ['activation_37[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)          (None, 7, 7, 192)            147456    ['average_pooling2d_3[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_30 (Ba  (None, 7, 7, 192)            576       ['conv2d_30[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_33 (Ba  (None, 7, 7, 192)            576       ['conv2d_33[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_38 (Ba  (None, 7, 7, 192)            576       ['conv2d_38[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_39 (Ba  (None, 7, 7, 192)            576       ['conv2d_39[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_30 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_30[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_33 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_33[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_38 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_38[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_39 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_39[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)        (None, 7, 7, 768)            0         ['activation_30[0][0]',       \n",
      "                                                                     'activation_33[0][0]',       \n",
      "                                                                     'activation_38[0][0]',       \n",
      "                                                                     'activation_39[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)          (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_44 (Ba  (None, 7, 7, 160)            480       ['conv2d_44[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_44 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_44[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_44[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_45 (Ba  (None, 7, 7, 160)            480       ['conv2d_45[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_45 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_45[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)          (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_45[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_41 (Ba  (None, 7, 7, 160)            480       ['conv2d_41[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_46 (Ba  (None, 7, 7, 160)            480       ['conv2d_46[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_41 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_41[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_46 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_46[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_41[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_46[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_42 (Ba  (None, 7, 7, 160)            480       ['conv2d_42[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_47 (Ba  (None, 7, 7, 160)            480       ['conv2d_47[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_42 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_42[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_47 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_47[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (Avera  (None, 7, 7, 768)            0         ['mixed4[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)          (None, 7, 7, 192)            215040    ['activation_42[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)          (None, 7, 7, 192)            215040    ['activation_47[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)          (None, 7, 7, 192)            147456    ['average_pooling2d_4[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_40 (Ba  (None, 7, 7, 192)            576       ['conv2d_40[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_43 (Ba  (None, 7, 7, 192)            576       ['conv2d_43[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_48 (Ba  (None, 7, 7, 192)            576       ['conv2d_48[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_49 (Ba  (None, 7, 7, 192)            576       ['conv2d_49[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_40 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_40[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_43 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_43[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_48 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_48[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_49 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_49[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)        (None, 7, 7, 768)            0         ['activation_40[0][0]',       \n",
      "                                                                     'activation_43[0][0]',       \n",
      "                                                                     'activation_48[0][0]',       \n",
      "                                                                     'activation_49[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)          (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_54 (Ba  (None, 7, 7, 160)            480       ['conv2d_54[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_54 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_54[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_54[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_55 (Ba  (None, 7, 7, 160)            480       ['conv2d_55[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_55 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_55[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)          (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_55[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_51 (Ba  (None, 7, 7, 160)            480       ['conv2d_51[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_56 (Ba  (None, 7, 7, 160)            480       ['conv2d_56[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_51 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_51[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_56 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_56[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_51[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_56[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_52 (Ba  (None, 7, 7, 160)            480       ['conv2d_52[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_57 (Ba  (None, 7, 7, 160)            480       ['conv2d_57[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_52 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_52[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_57 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_57[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (Avera  (None, 7, 7, 768)            0         ['mixed5[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)          (None, 7, 7, 192)            215040    ['activation_52[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)          (None, 7, 7, 192)            215040    ['activation_57[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)          (None, 7, 7, 192)            147456    ['average_pooling2d_5[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_50 (Ba  (None, 7, 7, 192)            576       ['conv2d_50[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_53 (Ba  (None, 7, 7, 192)            576       ['conv2d_53[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_58 (Ba  (None, 7, 7, 192)            576       ['conv2d_58[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_59 (Ba  (None, 7, 7, 192)            576       ['conv2d_59[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_50 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_50[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_53 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_53[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_58 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_58[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_59 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_59[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)        (None, 7, 7, 768)            0         ['activation_50[0][0]',       \n",
      "                                                                     'activation_53[0][0]',       \n",
      "                                                                     'activation_58[0][0]',       \n",
      "                                                                     'activation_59[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_64 (Ba  (None, 7, 7, 192)            576       ['conv2d_64[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_64 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_64[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_64[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_65 (Ba  (None, 7, 7, 192)            576       ['conv2d_65[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_65 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_65[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_65[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_61 (Ba  (None, 7, 7, 192)            576       ['conv2d_61[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_66 (Ba  (None, 7, 7, 192)            576       ['conv2d_66[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_61 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_61[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_66 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_66[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_61[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_66[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_62 (Ba  (None, 7, 7, 192)            576       ['conv2d_62[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_67 (Ba  (None, 7, 7, 192)            576       ['conv2d_67[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_62 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_62[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_67 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_67[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (Avera  (None, 7, 7, 768)            0         ['mixed6[0][0]']              \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_62[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_67[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)          (None, 7, 7, 192)            147456    ['average_pooling2d_6[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_60 (Ba  (None, 7, 7, 192)            576       ['conv2d_60[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_63 (Ba  (None, 7, 7, 192)            576       ['conv2d_63[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_68 (Ba  (None, 7, 7, 192)            576       ['conv2d_68[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_69 (Ba  (None, 7, 7, 192)            576       ['conv2d_69[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_60 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_60[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_63 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_63[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_68 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_68[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_69 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_69[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)        (None, 7, 7, 768)            0         ['activation_60[0][0]',       \n",
      "                                                                     'activation_63[0][0]',       \n",
      "                                                                     'activation_68[0][0]',       \n",
      "                                                                     'activation_69[0][0]']       \n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, 7, 7, 768)            1536      ['mixed7[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 37632)                0         ['layer_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64)                   2408512   ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 64)                   0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 6)                    390       ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11385702 (43.43 MB)\n",
      "Trainable params: 2410438 (9.20 MB)\n",
      "Non-trainable params: 8975264 (34.24 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Add Dense Layer\n",
    "x = layers.LayerNormalization()(last_output)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64,activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "model = Model(pre_trained_model.input, x)\n",
    "\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9349b5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T07:03:48.983072Z",
     "iopub.status.busy": "2024-06-06T07:03:48.982668Z",
     "iopub.status.idle": "2024-06-06T09:17:42.898442Z",
     "shell.execute_reply": "2024-06-06T09:17:42.897459Z"
    },
    "papermill": {
     "duration": 8033.993153,
     "end_time": "2024-06-06T09:17:42.900412",
     "exception": false,
     "start_time": "2024-06-06T07:03:48.907259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "113/113 [==============================] - 108s 921ms/step - loss: 1.1361 - accuracy: 0.5696 - precision: 0.7017 - recall: 0.4418 - val_loss: 0.5882 - val_accuracy: 0.7714 - val_precision: 0.8421 - val_recall: 0.6748\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 93s 824ms/step - loss: 0.6644 - accuracy: 0.7491 - precision: 0.8076 - recall: 0.6894 - val_loss: 0.4990 - val_accuracy: 0.8091 - val_precision: 0.8588 - val_recall: 0.7558\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 93s 822ms/step - loss: 0.5215 - accuracy: 0.8072 - precision: 0.8428 - recall: 0.7655 - val_loss: 0.4652 - val_accuracy: 0.8135 - val_precision: 0.8448 - val_recall: 0.7913\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 94s 833ms/step - loss: 0.4454 - accuracy: 0.8336 - precision: 0.8663 - recall: 0.8047 - val_loss: 0.3132 - val_accuracy: 0.8835 - val_precision: 0.9105 - val_recall: 0.8690\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 71s 623ms/step - loss: 0.3537 - accuracy: 0.8711 - precision: 0.8974 - recall: 0.8508 - val_loss: 0.3383 - val_accuracy: 0.8713 - val_precision: 0.8880 - val_recall: 0.8535\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - 99s 880ms/step - loss: 0.3316 - accuracy: 0.8747 - precision: 0.8987 - recall: 0.8558 - val_loss: 0.2368 - val_accuracy: 0.9068 - val_precision: 0.9277 - val_recall: 0.8968\n",
      "Epoch 7/100\n",
      "113/113 [==============================] - 81s 719ms/step - loss: 0.2890 - accuracy: 0.8947 - precision: 0.9120 - recall: 0.8755 - val_loss: 0.2673 - val_accuracy: 0.9046 - val_precision: 0.9253 - val_recall: 0.8935\n",
      "Epoch 8/100\n",
      "113/113 [==============================] - 95s 837ms/step - loss: 0.2872 - accuracy: 0.8944 - precision: 0.9143 - recall: 0.8805 - val_loss: 0.2216 - val_accuracy: 0.9267 - val_precision: 0.9350 - val_recall: 0.9101\n",
      "Epoch 9/100\n",
      "113/113 [==============================] - 72s 634ms/step - loss: 0.2489 - accuracy: 0.9094 - precision: 0.9238 - recall: 0.8961 - val_loss: 0.2094 - val_accuracy: 0.9245 - val_precision: 0.9327 - val_recall: 0.9223\n",
      "Epoch 10/100\n",
      "113/113 [==============================] - 73s 644ms/step - loss: 0.2414 - accuracy: 0.9133 - precision: 0.9271 - recall: 0.9011 - val_loss: 0.2022 - val_accuracy: 0.9201 - val_precision: 0.9309 - val_recall: 0.9123\n",
      "Epoch 11/100\n",
      "113/113 [==============================] - 91s 809ms/step - loss: 0.1962 - accuracy: 0.9300 - precision: 0.9399 - recall: 0.9205 - val_loss: 0.2004 - val_accuracy: 0.9301 - val_precision: 0.9388 - val_recall: 0.9201\n",
      "Epoch 12/100\n",
      "113/113 [==============================] - 73s 647ms/step - loss: 0.1958 - accuracy: 0.9269 - precision: 0.9379 - recall: 0.9183 - val_loss: 0.2008 - val_accuracy: 0.9245 - val_precision: 0.9345 - val_recall: 0.9179\n",
      "Epoch 13/100\n",
      "113/113 [==============================] - 104s 921ms/step - loss: 0.1832 - accuracy: 0.9353 - precision: 0.9463 - recall: 0.9250 - val_loss: 0.1623 - val_accuracy: 0.9489 - val_precision: 0.9526 - val_recall: 0.9378\n",
      "Epoch 14/100\n",
      "113/113 [==============================] - 83s 736ms/step - loss: 0.1766 - accuracy: 0.9344 - precision: 0.9429 - recall: 0.9275 - val_loss: 0.1491 - val_accuracy: 0.9401 - val_precision: 0.9525 - val_recall: 0.9345\n",
      "Epoch 15/100\n",
      "113/113 [==============================] - 74s 651ms/step - loss: 0.1761 - accuracy: 0.9403 - precision: 0.9493 - recall: 0.9314 - val_loss: 0.1753 - val_accuracy: 0.9434 - val_precision: 0.9507 - val_recall: 0.9423\n",
      "Epoch 16/100\n",
      "113/113 [==============================] - 84s 742ms/step - loss: 0.1629 - accuracy: 0.9475 - precision: 0.9525 - recall: 0.9408 - val_loss: 0.1603 - val_accuracy: 0.9412 - val_precision: 0.9481 - val_recall: 0.9334\n",
      "Epoch 17/100\n",
      "113/113 [==============================] - 75s 660ms/step - loss: 0.1489 - accuracy: 0.9475 - precision: 0.9542 - recall: 0.9433 - val_loss: 0.1872 - val_accuracy: 0.9401 - val_precision: 0.9471 - val_recall: 0.9345\n",
      "Epoch 18/100\n",
      "113/113 [==============================] - 72s 633ms/step - loss: 0.1438 - accuracy: 0.9467 - precision: 0.9528 - recall: 0.9419 - val_loss: 0.1516 - val_accuracy: 0.9434 - val_precision: 0.9494 - val_recall: 0.9378\n",
      "Epoch 19/100\n",
      "113/113 [==============================] - 72s 634ms/step - loss: 0.1500 - accuracy: 0.9467 - precision: 0.9516 - recall: 0.9403 - val_loss: 0.1861 - val_accuracy: 0.9367 - val_precision: 0.9459 - val_recall: 0.9323\n",
      "Epoch 20/100\n",
      "113/113 [==============================] - 101s 891ms/step - loss: 0.1307 - accuracy: 0.9522 - precision: 0.9576 - recall: 0.9483 - val_loss: 0.1416 - val_accuracy: 0.9501 - val_precision: 0.9531 - val_recall: 0.9478\n",
      "Epoch 21/100\n",
      "113/113 [==============================] - 91s 802ms/step - loss: 0.1315 - accuracy: 0.9544 - precision: 0.9595 - recall: 0.9480 - val_loss: 0.1264 - val_accuracy: 0.9523 - val_precision: 0.9565 - val_recall: 0.9512\n",
      "Epoch 22/100\n",
      "113/113 [==============================] - 80s 708ms/step - loss: 0.1146 - accuracy: 0.9597 - precision: 0.9633 - recall: 0.9550 - val_loss: 0.1381 - val_accuracy: 0.9512 - val_precision: 0.9585 - val_recall: 0.9478\n",
      "Epoch 23/100\n",
      "113/113 [==============================] - 70s 617ms/step - loss: 0.1127 - accuracy: 0.9611 - precision: 0.9644 - recall: 0.9561 - val_loss: 0.1525 - val_accuracy: 0.9478 - val_precision: 0.9539 - val_recall: 0.9412\n",
      "Epoch 24/100\n",
      "113/113 [==============================] - 80s 705ms/step - loss: 0.1081 - accuracy: 0.9594 - precision: 0.9649 - recall: 0.9558 - val_loss: 0.1568 - val_accuracy: 0.9456 - val_precision: 0.9528 - val_recall: 0.9412\n",
      "Epoch 25/100\n",
      "113/113 [==============================] - 90s 795ms/step - loss: 0.1013 - accuracy: 0.9650 - precision: 0.9673 - recall: 0.9625 - val_loss: 0.1496 - val_accuracy: 0.9534 - val_precision: 0.9542 - val_recall: 0.9489\n",
      "Epoch 26/100\n",
      "113/113 [==============================] - 70s 617ms/step - loss: 0.1067 - accuracy: 0.9639 - precision: 0.9680 - recall: 0.9589 - val_loss: 0.1592 - val_accuracy: 0.9512 - val_precision: 0.9562 - val_recall: 0.9456\n",
      "Epoch 27/100\n",
      "113/113 [==============================] - 99s 881ms/step - loss: 0.0997 - accuracy: 0.9697 - precision: 0.9726 - recall: 0.9661 - val_loss: 0.1155 - val_accuracy: 0.9612 - val_precision: 0.9642 - val_recall: 0.9578\n",
      "Epoch 28/100\n",
      "113/113 [==============================] - 70s 618ms/step - loss: 0.0950 - accuracy: 0.9678 - precision: 0.9715 - recall: 0.9647 - val_loss: 0.1933 - val_accuracy: 0.9323 - val_precision: 0.9353 - val_recall: 0.9312\n",
      "Epoch 29/100\n",
      "113/113 [==============================] - 89s 792ms/step - loss: 0.0920 - accuracy: 0.9667 - precision: 0.9701 - recall: 0.9650 - val_loss: 0.1095 - val_accuracy: 0.9634 - val_precision: 0.9633 - val_recall: 0.9612\n",
      "Epoch 30/100\n",
      "113/113 [==============================] - 79s 702ms/step - loss: 0.0974 - accuracy: 0.9650 - precision: 0.9684 - recall: 0.9636 - val_loss: 0.1316 - val_accuracy: 0.9523 - val_precision: 0.9543 - val_recall: 0.9512\n",
      "Epoch 31/100\n",
      "113/113 [==============================] - 70s 616ms/step - loss: 0.0905 - accuracy: 0.9680 - precision: 0.9706 - recall: 0.9639 - val_loss: 0.1798 - val_accuracy: 0.9378 - val_precision: 0.9387 - val_recall: 0.9345\n",
      "Epoch 32/100\n",
      "113/113 [==============================] - 70s 617ms/step - loss: 0.0834 - accuracy: 0.9697 - precision: 0.9732 - recall: 0.9672 - val_loss: 0.1195 - val_accuracy: 0.9534 - val_precision: 0.9555 - val_recall: 0.9534\n",
      "Epoch 33/100\n",
      "113/113 [==============================] - 79s 700ms/step - loss: 0.0764 - accuracy: 0.9703 - precision: 0.9740 - recall: 0.9692 - val_loss: 0.1165 - val_accuracy: 0.9589 - val_precision: 0.9588 - val_recall: 0.9556\n",
      "Epoch 34/100\n",
      "113/113 [==============================] - 79s 701ms/step - loss: 0.0734 - accuracy: 0.9744 - precision: 0.9763 - recall: 0.9733 - val_loss: 0.1355 - val_accuracy: 0.9512 - val_precision: 0.9522 - val_recall: 0.9501\n",
      "Epoch 35/100\n",
      "113/113 [==============================] - 79s 699ms/step - loss: 0.0889 - accuracy: 0.9692 - precision: 0.9726 - recall: 0.9678 - val_loss: 0.1368 - val_accuracy: 0.9523 - val_precision: 0.9543 - val_recall: 0.9512\n",
      "Epoch 36/100\n",
      "113/113 [==============================] - 80s 709ms/step - loss: 0.0839 - accuracy: 0.9672 - precision: 0.9696 - recall: 0.9650 - val_loss: 0.1348 - val_accuracy: 0.9578 - val_precision: 0.9598 - val_recall: 0.9545\n",
      "Epoch 37/100\n",
      "113/113 [==============================] - 71s 628ms/step - loss: 0.0797 - accuracy: 0.9683 - precision: 0.9694 - recall: 0.9667 - val_loss: 0.1240 - val_accuracy: 0.9589 - val_precision: 0.9632 - val_recall: 0.9578\n",
      "Epoch 38/100\n",
      "113/113 [==============================] - 80s 707ms/step - loss: 0.0763 - accuracy: 0.9755 - precision: 0.9785 - recall: 0.9736 - val_loss: 0.1097 - val_accuracy: 0.9612 - val_precision: 0.9632 - val_recall: 0.9589\n",
      "Epoch 39/100\n",
      "113/113 [==============================] - 79s 702ms/step - loss: 0.0709 - accuracy: 0.9750 - precision: 0.9769 - recall: 0.9742 - val_loss: 0.1105 - val_accuracy: 0.9623 - val_precision: 0.9632 - val_recall: 0.9589\n",
      "Epoch 40/100\n",
      "113/113 [==============================] - 70s 616ms/step - loss: 0.0696 - accuracy: 0.9739 - precision: 0.9763 - recall: 0.9722 - val_loss: 0.1591 - val_accuracy: 0.9489 - val_precision: 0.9531 - val_recall: 0.9478\n",
      "Epoch 41/100\n",
      "113/113 [==============================] - 80s 709ms/step - loss: 0.0764 - accuracy: 0.9742 - precision: 0.9763 - recall: 0.9719 - val_loss: 0.1386 - val_accuracy: 0.9556 - val_precision: 0.9566 - val_recall: 0.9545\n",
      "Epoch 42/100\n",
      "113/113 [==============================] - 70s 620ms/step - loss: 0.0587 - accuracy: 0.9803 - precision: 0.9816 - recall: 0.9789 - val_loss: 0.1286 - val_accuracy: 0.9567 - val_precision: 0.9576 - val_recall: 0.9523\n",
      "Epoch 43/100\n",
      "113/113 [==============================] - 100s 882ms/step - loss: 0.0638 - accuracy: 0.9797 - precision: 0.9810 - recall: 0.9769 - val_loss: 0.1250 - val_accuracy: 0.9645 - val_precision: 0.9644 - val_recall: 0.9612\n",
      "Epoch 44/100\n",
      "113/113 [==============================] - 80s 708ms/step - loss: 0.0683 - accuracy: 0.9794 - precision: 0.9816 - recall: 0.9792 - val_loss: 0.1380 - val_accuracy: 0.9612 - val_precision: 0.9611 - val_recall: 0.9600\n",
      "Epoch 45/100\n",
      "113/113 [==============================] - 70s 618ms/step - loss: 0.0683 - accuracy: 0.9786 - precision: 0.9805 - recall: 0.9767 - val_loss: 0.1237 - val_accuracy: 0.9545 - val_precision: 0.9555 - val_recall: 0.9523\n",
      "Epoch 46/100\n",
      "113/113 [==============================] - 80s 706ms/step - loss: 0.0658 - accuracy: 0.9778 - precision: 0.9794 - recall: 0.9761 - val_loss: 0.1383 - val_accuracy: 0.9556 - val_precision: 0.9577 - val_recall: 0.9545\n",
      "Epoch 47/100\n",
      "113/113 [==============================] - 70s 622ms/step - loss: 0.0723 - accuracy: 0.9764 - precision: 0.9774 - recall: 0.9744 - val_loss: 0.1242 - val_accuracy: 0.9623 - val_precision: 0.9622 - val_recall: 0.9612\n",
      "Epoch 48/100\n",
      "113/113 [==============================] - 70s 621ms/step - loss: 0.0612 - accuracy: 0.9783 - precision: 0.9797 - recall: 0.9772 - val_loss: 0.1112 - val_accuracy: 0.9578 - val_precision: 0.9599 - val_recall: 0.9556\n",
      "Epoch 49/100\n",
      "113/113 [==============================] - 92s 815ms/step - loss: 0.0568 - accuracy: 0.9792 - precision: 0.9805 - recall: 0.9783 - val_loss: 0.1227 - val_accuracy: 0.9667 - val_precision: 0.9699 - val_recall: 0.9656\n",
      "Epoch 50/100\n",
      "113/113 [==============================] - 74s 649ms/step - loss: 0.0520 - accuracy: 0.9803 - precision: 0.9819 - recall: 0.9789 - val_loss: 0.1276 - val_accuracy: 0.9589 - val_precision: 0.9588 - val_recall: 0.9556\n",
      "Epoch 51/100\n",
      "113/113 [==============================] - 70s 620ms/step - loss: 0.0615 - accuracy: 0.9803 - precision: 0.9808 - recall: 0.9783 - val_loss: 0.1404 - val_accuracy: 0.9578 - val_precision: 0.9588 - val_recall: 0.9567\n",
      "Epoch 52/100\n",
      "113/113 [==============================] - 80s 710ms/step - loss: 0.0591 - accuracy: 0.9792 - precision: 0.9816 - recall: 0.9780 - val_loss: 0.0940 - val_accuracy: 0.9645 - val_precision: 0.9677 - val_recall: 0.9634\n",
      "Epoch 53/100\n",
      "113/113 [==============================] - 71s 622ms/step - loss: 0.0536 - accuracy: 0.9817 - precision: 0.9836 - recall: 0.9803 - val_loss: 0.1471 - val_accuracy: 0.9567 - val_precision: 0.9588 - val_recall: 0.9556\n",
      "Epoch 54/100\n",
      "113/113 [==============================] - 88s 782ms/step - loss: 0.0561 - accuracy: 0.9819 - precision: 0.9827 - recall: 0.9806 - val_loss: 0.1004 - val_accuracy: 0.9689 - val_precision: 0.9689 - val_recall: 0.9667\n",
      "Epoch 55/100\n",
      "113/113 [==============================] - 70s 617ms/step - loss: 0.0612 - accuracy: 0.9794 - precision: 0.9802 - recall: 0.9783 - val_loss: 0.1069 - val_accuracy: 0.9667 - val_precision: 0.9688 - val_recall: 0.9645\n",
      "Epoch 56/100\n",
      "113/113 [==============================] - 80s 701ms/step - loss: 0.0544 - accuracy: 0.9806 - precision: 0.9819 - recall: 0.9797 - val_loss: 0.1421 - val_accuracy: 0.9489 - val_precision: 0.9541 - val_recall: 0.9467\n",
      "Epoch 57/100\n",
      "113/113 [==============================] - 70s 614ms/step - loss: 0.0562 - accuracy: 0.9811 - precision: 0.9822 - recall: 0.9806 - val_loss: 0.1381 - val_accuracy: 0.9600 - val_precision: 0.9622 - val_recall: 0.9600\n",
      "Epoch 58/100\n",
      "113/113 [==============================] - 73s 639ms/step - loss: 0.0487 - accuracy: 0.9842 - precision: 0.9850 - recall: 0.9831 - val_loss: 0.1322 - val_accuracy: 0.9667 - val_precision: 0.9688 - val_recall: 0.9656\n",
      "Epoch 59/100\n",
      "113/113 [==============================] - 80s 708ms/step - loss: 0.0477 - accuracy: 0.9822 - precision: 0.9827 - recall: 0.9814 - val_loss: 0.1711 - val_accuracy: 0.9478 - val_precision: 0.9529 - val_recall: 0.9423\n",
      "Epoch 60/100\n",
      "113/113 [==============================] - 71s 631ms/step - loss: 0.0589 - accuracy: 0.9808 - precision: 0.9824 - recall: 0.9797 - val_loss: 0.0964 - val_accuracy: 0.9678 - val_precision: 0.9700 - val_recall: 0.9678\n",
      "Epoch 61/100\n",
      "113/113 [==============================] - 69s 615ms/step - loss: 0.0500 - accuracy: 0.9847 - precision: 0.9853 - recall: 0.9842 - val_loss: 0.1248 - val_accuracy: 0.9645 - val_precision: 0.9688 - val_recall: 0.9634\n",
      "Epoch 62/100\n",
      "113/113 [==============================] - 80s 706ms/step - loss: 0.0437 - accuracy: 0.9850 - precision: 0.9858 - recall: 0.9836 - val_loss: 0.1520 - val_accuracy: 0.9623 - val_precision: 0.9633 - val_recall: 0.9612\n",
      "Epoch 63/100\n",
      "113/113 [==============================] - 72s 632ms/step - loss: 0.0585 - accuracy: 0.9817 - precision: 0.9827 - recall: 0.9806 - val_loss: 0.1165 - val_accuracy: 0.9656 - val_precision: 0.9666 - val_recall: 0.9634\n",
      "Epoch 64/100\n",
      "113/113 [==============================] - 71s 626ms/step - loss: 0.0419 - accuracy: 0.9853 - precision: 0.9861 - recall: 0.9850 - val_loss: 0.0937 - val_accuracy: 0.9667 - val_precision: 0.9667 - val_recall: 0.9656\n",
      "Epoch 65/100\n",
      "113/113 [==============================] - 71s 629ms/step - loss: 0.0572 - accuracy: 0.9794 - precision: 0.9808 - recall: 0.9786 - val_loss: 0.1037 - val_accuracy: 0.9678 - val_precision: 0.9699 - val_recall: 0.9656\n",
      "Epoch 66/100\n",
      "113/113 [==============================] - 91s 801ms/step - loss: 0.0523 - accuracy: 0.9831 - precision: 0.9833 - recall: 0.9828 - val_loss: 0.1157 - val_accuracy: 0.9711 - val_precision: 0.9710 - val_recall: 0.9678\n",
      "Epoch 67/100\n",
      "113/113 [==============================] - 73s 651ms/step - loss: 0.0484 - accuracy: 0.9825 - precision: 0.9836 - recall: 0.9817 - val_loss: 0.1232 - val_accuracy: 0.9612 - val_precision: 0.9612 - val_recall: 0.9612\n",
      "Epoch 68/100\n",
      "113/113 [==============================] - 72s 641ms/step - loss: 0.0418 - accuracy: 0.9856 - precision: 0.9864 - recall: 0.9847 - val_loss: 0.1189 - val_accuracy: 0.9612 - val_precision: 0.9611 - val_recall: 0.9600\n",
      "Epoch 69/100\n",
      "113/113 [==============================] - 72s 634ms/step - loss: 0.0414 - accuracy: 0.9867 - precision: 0.9875 - recall: 0.9861 - val_loss: 0.0973 - val_accuracy: 0.9678 - val_precision: 0.9700 - val_recall: 0.9678\n",
      "Epoch 70/100\n",
      "113/113 [==============================] - 71s 627ms/step - loss: 0.0444 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9861 - val_loss: 0.1858 - val_accuracy: 0.9523 - val_precision: 0.9544 - val_recall: 0.9523\n",
      "Epoch 71/100\n",
      "113/113 [==============================] - 70s 613ms/step - loss: 0.0400 - accuracy: 0.9869 - precision: 0.9878 - recall: 0.9861 - val_loss: 0.1078 - val_accuracy: 0.9700 - val_precision: 0.9700 - val_recall: 0.9700\n",
      "Epoch 72/100\n",
      "113/113 [==============================] - 69s 611ms/step - loss: 0.0402 - accuracy: 0.9869 - precision: 0.9872 - recall: 0.9861 - val_loss: 0.1112 - val_accuracy: 0.9678 - val_precision: 0.9678 - val_recall: 0.9667\n",
      "Epoch 73/100\n",
      "113/113 [==============================] - 70s 621ms/step - loss: 0.0572 - accuracy: 0.9789 - precision: 0.9799 - recall: 0.9775 - val_loss: 0.0990 - val_accuracy: 0.9700 - val_precision: 0.9700 - val_recall: 0.9678\n",
      "Epoch 74/100\n",
      "113/113 [==============================] - 69s 609ms/step - loss: 0.0300 - accuracy: 0.9906 - precision: 0.9919 - recall: 0.9900 - val_loss: 0.1036 - val_accuracy: 0.9700 - val_precision: 0.9700 - val_recall: 0.9700\n",
      "Epoch 75/100\n",
      "113/113 [==============================] - 70s 618ms/step - loss: 0.0449 - accuracy: 0.9869 - precision: 0.9880 - recall: 0.9861 - val_loss: 0.1157 - val_accuracy: 0.9634 - val_precision: 0.9634 - val_recall: 0.9634\n",
      "Epoch 76/100\n",
      "113/113 [==============================] - 73s 641ms/step - loss: 0.0380 - accuracy: 0.9883 - precision: 0.9889 - recall: 0.9875 - val_loss: 0.1220 - val_accuracy: 0.9656 - val_precision: 0.9666 - val_recall: 0.9645\n",
      "Epoch 77/100\n",
      "113/113 [==============================] - 70s 620ms/step - loss: 0.0373 - accuracy: 0.9858 - precision: 0.9869 - recall: 0.9856 - val_loss: 0.1154 - val_accuracy: 0.9700 - val_precision: 0.9711 - val_recall: 0.9700\n",
      "Epoch 78/100\n",
      "113/113 [==============================] - 100s 882ms/step - loss: 0.0309 - accuracy: 0.9886 - precision: 0.9892 - recall: 0.9886 - val_loss: 0.0807 - val_accuracy: 0.9756 - val_precision: 0.9756 - val_recall: 0.9745\n",
      "Epoch 79/100\n",
      "113/113 [==============================] - 70s 617ms/step - loss: 0.0374 - accuracy: 0.9883 - precision: 0.9886 - recall: 0.9881 - val_loss: 0.0883 - val_accuracy: 0.9756 - val_precision: 0.9756 - val_recall: 0.9756\n",
      "Epoch 80/100\n",
      "113/113 [==============================] - 80s 706ms/step - loss: 0.0470 - accuracy: 0.9836 - precision: 0.9841 - recall: 0.9831 - val_loss: 0.1268 - val_accuracy: 0.9645 - val_precision: 0.9688 - val_recall: 0.9634\n",
      "Epoch 81/100\n",
      "113/113 [==============================] - 78s 693ms/step - loss: 0.0419 - accuracy: 0.9856 - precision: 0.9864 - recall: 0.9853 - val_loss: 0.1545 - val_accuracy: 0.9567 - val_precision: 0.9567 - val_recall: 0.9567\n",
      "Epoch 82/100\n",
      "113/113 [==============================] - 72s 634ms/step - loss: 0.0407 - accuracy: 0.9853 - precision: 0.9861 - recall: 0.9844 - val_loss: 0.1131 - val_accuracy: 0.9667 - val_precision: 0.9678 - val_recall: 0.9667\n",
      "Epoch 83/100\n",
      "113/113 [==============================] - 70s 621ms/step - loss: 0.0296 - accuracy: 0.9900 - precision: 0.9914 - recall: 0.9883 - val_loss: 0.0970 - val_accuracy: 0.9711 - val_precision: 0.9722 - val_recall: 0.9711\n",
      "Epoch 84/100\n",
      "113/113 [==============================] - 68s 598ms/step - loss: 0.0419 - accuracy: 0.9878 - precision: 0.9883 - recall: 0.9869 - val_loss: 0.1490 - val_accuracy: 0.9545 - val_precision: 0.9545 - val_recall: 0.9545\n",
      "Epoch 85/100\n",
      "113/113 [==============================] - 78s 691ms/step - loss: 0.0354 - accuracy: 0.9881 - precision: 0.9892 - recall: 0.9881 - val_loss: 0.1149 - val_accuracy: 0.9678 - val_precision: 0.9689 - val_recall: 0.9678\n",
      "Epoch 86/100\n",
      "113/113 [==============================] - 70s 621ms/step - loss: 0.0499 - accuracy: 0.9836 - precision: 0.9841 - recall: 0.9828 - val_loss: 0.1419 - val_accuracy: 0.9667 - val_precision: 0.9667 - val_recall: 0.9656\n",
      "Epoch 87/100\n",
      "113/113 [==============================] - 70s 617ms/step - loss: 0.0397 - accuracy: 0.9875 - precision: 0.9886 - recall: 0.9872 - val_loss: 0.1137 - val_accuracy: 0.9667 - val_precision: 0.9667 - val_recall: 0.9667\n",
      "Epoch 88/100\n",
      "113/113 [==============================] - 79s 701ms/step - loss: 0.0330 - accuracy: 0.9886 - precision: 0.9894 - recall: 0.9881 - val_loss: 0.0930 - val_accuracy: 0.9678 - val_precision: 0.9689 - val_recall: 0.9678\n",
      "Epoch 89/100\n",
      "113/113 [==============================] - 69s 608ms/step - loss: 0.0446 - accuracy: 0.9864 - precision: 0.9869 - recall: 0.9858 - val_loss: 0.1201 - val_accuracy: 0.9612 - val_precision: 0.9611 - val_recall: 0.9600\n",
      "Epoch 90/100\n",
      "113/113 [==============================] - 68s 605ms/step - loss: 0.0327 - accuracy: 0.9914 - precision: 0.9922 - recall: 0.9914 - val_loss: 0.0962 - val_accuracy: 0.9700 - val_precision: 0.9722 - val_recall: 0.9700\n",
      "Epoch 91/100\n",
      "113/113 [==============================] - 69s 608ms/step - loss: 0.0410 - accuracy: 0.9861 - precision: 0.9866 - recall: 0.9853 - val_loss: 0.0993 - val_accuracy: 0.9700 - val_precision: 0.9700 - val_recall: 0.9700\n",
      "Epoch 92/100\n",
      "113/113 [==============================] - 69s 607ms/step - loss: 0.0355 - accuracy: 0.9881 - precision: 0.9889 - recall: 0.9878 - val_loss: 0.0994 - val_accuracy: 0.9700 - val_precision: 0.9700 - val_recall: 0.9700\n",
      "Epoch 93/100\n",
      "113/113 [==============================] - 70s 616ms/step - loss: 0.0359 - accuracy: 0.9861 - precision: 0.9867 - recall: 0.9858 - val_loss: 0.1184 - val_accuracy: 0.9623 - val_precision: 0.9654 - val_recall: 0.9612\n",
      "Epoch 94/100\n",
      "113/113 [==============================] - 70s 617ms/step - loss: 0.0353 - accuracy: 0.9881 - precision: 0.9889 - recall: 0.9878 - val_loss: 0.1164 - val_accuracy: 0.9623 - val_precision: 0.9633 - val_recall: 0.9623\n",
      "Epoch 95/100\n",
      "113/113 [==============================] - 70s 621ms/step - loss: 0.0404 - accuracy: 0.9850 - precision: 0.9855 - recall: 0.9842 - val_loss: 0.1063 - val_accuracy: 0.9745 - val_precision: 0.9745 - val_recall: 0.9745\n",
      "Epoch 96/100\n",
      "113/113 [==============================] - 70s 620ms/step - loss: 0.0259 - accuracy: 0.9911 - precision: 0.9914 - recall: 0.9908 - val_loss: 0.0901 - val_accuracy: 0.9734 - val_precision: 0.9755 - val_recall: 0.9734\n",
      "Epoch 97/100\n",
      "113/113 [==============================] - 70s 617ms/step - loss: 0.0420 - accuracy: 0.9869 - precision: 0.9875 - recall: 0.9869 - val_loss: 0.1461 - val_accuracy: 0.9623 - val_precision: 0.9644 - val_recall: 0.9623\n",
      "Epoch 98/100\n",
      "113/113 [==============================] - 69s 608ms/step - loss: 0.0336 - accuracy: 0.9897 - precision: 0.9900 - recall: 0.9892 - val_loss: 0.0996 - val_accuracy: 0.9634 - val_precision: 0.9655 - val_recall: 0.9623\n",
      "Epoch 99/100\n",
      "113/113 [==============================] - 69s 614ms/step - loss: 0.0349 - accuracy: 0.9878 - precision: 0.9880 - recall: 0.9875 - val_loss: 0.1118 - val_accuracy: 0.9634 - val_precision: 0.9655 - val_recall: 0.9623\n",
      "Epoch 100/100\n",
      "113/113 [==============================] - 69s 613ms/step - loss: 0.0301 - accuracy: 0.9892 - precision: 0.9894 - recall: 0.9883 - val_loss: 0.1553 - val_accuracy: 0.9623 - val_precision: 0.9644 - val_recall: 0.9612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7b18fc1e9870>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train Model\n",
    "checkpoint_filepath = \"/kaggle/working/checkpoint\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "model.fit(train_generator,\n",
    "                  epochs=100,\n",
    "                  validation_data=validation_generator, \n",
    "                callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f5c934a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:17:44.979369Z",
     "iopub.status.busy": "2024-06-06T09:17:44.978990Z",
     "iopub.status.idle": "2024-06-06T09:18:53.880944Z",
     "shell.execute_reply": "2024-06-06T09:18:53.880217Z"
    },
    "papermill": {
     "duration": 69.909758,
     "end_time": "2024-06-06T09:18:53.882855",
     "exception": false,
     "start_time": "2024-06-06T09:17:43.973097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 57s 503ms/step - loss: 0.0111 - accuracy: 0.9964 - precision: 0.9972 - recall: 0.9961\n",
      "29/29 [==============================] - 11s 393ms/step - loss: 0.1553 - accuracy: 0.9623 - precision: 0.9644 - recall: 0.9612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15534178912639618,\n",
       " 0.9622641801834106,\n",
       " 0.9643652439117432,\n",
       " 0.9611542820930481]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_generator)\n",
    "model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc1c7756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:18:55.979131Z",
     "iopub.status.busy": "2024-06-06T09:18:55.978662Z",
     "iopub.status.idle": "2024-06-06T09:18:55.984399Z",
     "shell.execute_reply": "2024-06-06T09:18:55.983453Z"
    },
    "papermill": {
     "duration": 1.063632,
     "end_time": "2024-06-06T09:18:55.986358",
     "exception": false,
     "start_time": "2024-06-06T09:18:54.922726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dandruff', 'dermatitis', 'earinfection', 'fleas', 'ringworm', 'skintumors']\n"
     ]
    }
   ],
   "source": [
    "class_map = train_generator.class_indices\n",
    "classes_disease = []\n",
    "for key in class_map.keys():\n",
    "    classes_disease.append(key)\n",
    "print(classes_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15deb462",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:18:58.149742Z",
     "iopub.status.busy": "2024-06-06T09:18:58.148894Z",
     "iopub.status.idle": "2024-06-06T09:18:59.668612Z",
     "shell.execute_reply": "2024-06-06T09:18:59.667735Z"
    },
    "papermill": {
     "duration": 2.567485,
     "end_time": "2024-06-06T09:18:59.670528",
     "exception": false,
     "start_time": "2024-06-06T09:18:57.103043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 999ms/step\n",
      "skintumors_dark_181.png\n",
      "[1.6381193e-12 1.8913893e-06 9.1918417e-16 4.4890380e-11 3.9307542e-06\n",
      " 9.9999416e-01]\n",
      "skintumors\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "fleas_flips_53.png\n",
      "[2.8243997e-07 6.2327252e-17 6.7277234e-18 9.9999976e-01 3.7760871e-17\n",
      " 2.3990292e-16]\n",
      "fleas\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "earinfection_flips_153.png\n",
      "[3.6641727e-16 2.7581249e-19 1.0000000e+00 1.0550631e-22 7.7407756e-21\n",
      " 1.9306151e-19]\n",
      "earinfection\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "dandruff_flips_271.png\n",
      "[1.0000000e+00 4.0523235e-18 2.4745253e-21 1.2910326e-10 5.5642463e-16\n",
      " 1.5635893e-10]\n",
      "dandruff\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "lickgranuloma35 - Copy (2).png\n",
      "[5.2640161e-19 1.0000000e+00 2.5227624e-14 7.6545466e-14 1.5537763e-09\n",
      " 9.6775556e-12]\n",
      "dermatitis\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "ringworm_flips_218.png\n",
      "[1.6670269e-12 9.8546523e-05 2.1099640e-10 1.0439861e-10 9.9990129e-01\n",
      " 7.6156908e-08]\n",
      "ringworm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "for i in os.listdir('/kaggle/working/validation'):\n",
    "    for j in os.listdir('/kaggle/working/validation/'+i):\n",
    "        path='/kaggle/working/validation/'+i+'/'+j\n",
    "        img = load_img(path, target_size=(150, 150))\n",
    "        x = img_to_array(img)\n",
    "        x /= 255\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        image_tensor = np.vstack([x])\n",
    "        classes = model.predict(image_tensor)\n",
    "        print(j)\n",
    "        print(classes[0])\n",
    "        print(classes_disease[np.argmax(classes[0])])\n",
    "        break\n",
    "\n",
    "        \n",
    "# path = '/kaggle/working/validation/ringworm/ringworm_dark_40.png'\n",
    "# img = load_img(path, target_size=(150, 150))\n",
    "# x = img_to_array(img)\n",
    "# x /= 255\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# image_tensor = np.vstack([x])\n",
    "# classes = model.predict(image_tensor)\n",
    "# print(classes[0])\n",
    "# print(np.argmax(classes[0]))\n",
    "# print(classes_disease[np.argmax(classes[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6fc41ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T09:19:01.799679Z",
     "iopub.status.busy": "2024-06-06T09:19:01.799295Z",
     "iopub.status.idle": "2024-06-06T09:19:02.153214Z",
     "shell.execute_reply": "2024-06-06T09:19:02.152352Z"
    },
    "papermill": {
     "duration": 1.454367,
     "end_time": "2024-06-06T09:19:02.155633",
     "exception": false,
     "start_time": "2024-06-06T09:19:00.701266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model_saved.h5\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5145223,
     "sourceId": 8599965,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8237.777878,
   "end_time": "2024-06-06T09:19:05.942607",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-06T07:01:48.164729",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
